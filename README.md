# ðŸ¦œðŸ”— LangChain Doc Chat - Experience LLAMA 3.1

Leveraging Your Documents in a LangChain Pipeline: RAG Implementation
This project highlights how to leverage a ChromaDB vectorstore in a Langchain pipeline to create a LangChain Doc Chat with LLAMA 3.1 . You can load in a pdf based document and use it alongside an LLM without the need for fine tuning. 


# Startup ðŸš€
1. Create a virtual environment `python -m venv langchainenv`
2. Activate it: 
   - Windows:`.\langchainenv\Scripts\activate`
   - Mac: `source langchain/bin/activate`
3. Clone this repo `git clone https://github.com/lovesaif/LangchainDocumentsChatbot.git`
4. Go into the directory `cd LangchainDocumentsChatbot
`
5. Install the required dependencies `pip install -r requirements.txt`
6. Add your Groq APIKey in file `app.py`
7. Start the app `streamlit run app.py`  

# Other References ðŸ”—
<p>The main LG Agent used:<a href="https://python.langchain.com/docs/introduction/">Langchain VectorStore Agents
</a></p>
